{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f961b778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 11:17:02.486684: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from random import seed\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b7f4d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c5ad476",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # Clears the default graph stack and resets the global default graph\n",
    "file1 = \"example_expression.csv\"\n",
    "file2 = 'example_adjacency.txt'\n",
    "out_file = 'var_impo.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80dbacb",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd4b81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression\n",
    "expression = np.loadtxt(file1, dtype=float, delimiter=\",\")\n",
    "label_vec = np.array(expression[:,-1], dtype=int) # y (m x 1)\n",
    "expression = np.array(expression[:,:-1]) # x  (m x p)\n",
    "\n",
    "labels = []\n",
    "for l in label_vec:\n",
    "    if l == 1:\n",
    "        labels.append([0,1])\n",
    "    else:\n",
    "        labels.append([1,0])\n",
    "labels = np.array(labels,dtype=int)\n",
    "\n",
    "# interaction between features\n",
    "partition = np.loadtxt(file2, dtype=int, delimiter=None) # p x p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0943bf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db581429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf02eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edcab715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f9445",
   "metadata": {},
   "source": [
    "# split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a13f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(0.8*expression.shape[0])\n",
    "\n",
    "expression, labels = shuffle(expression, labels)\n",
    "x_train = expression[:cut, :]\n",
    "x_test = expression[cut:, :]\n",
    "y_train = labels[:cut, :]\n",
    "y_test = labels[cut:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cff44e",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "864611a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper-parameters and settings\n",
    "L2 = False\n",
    "max_pooling = False\n",
    "droph1 = False\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 100\n",
    "batch_size = 8\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8a5b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the constant limit for feature selection. for the feature has more than 50 features, replace with 50\n",
    "gamma_c = 50\n",
    "gamma_numerator = np.sum(partition, axis=0)\n",
    "gamma_denominator = np.sum(partition, axis=0)\n",
    "gamma_numerator[np.where(gamma_numerator>gamma_c)] = gamma_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ee7c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify layer node number\n",
    "n_hidden_1 = np.shape(partition)[0] # dense layer\n",
    "n_hidden_2 = 64 # \n",
    "n_hidden_3 = 16\n",
    "n_classes = 2\n",
    "n_features = np.shape(expression)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d514291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initiate training logs\n",
    "loss_rec = np.zeros([training_epochs, 1])\n",
    "training_eval = np.zeros([training_epochs, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6b40f",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "399b932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(mat): ## input {mat}rix\n",
    "\n",
    "    def max_pool_one(instance):\n",
    "        return tf.reduce_max(tf.multiply(tf.matmul(tf.reshape(instance, [n_features, 1]), tf.ones([1, n_features]))\n",
    "                                         , partition)\n",
    "                             , axis=0)\n",
    "\n",
    "    out = tf.map_fn(max_pool_one, mat, parallel_iterations=1000, swap_memory=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae041ce",
   "metadata": {},
   "source": [
    "https://ai.stackexchange.com/questions/9563/is-pooling-a-kind-of-dropout\n",
    "Dropout and Max-pooling are performed for different reasons.\n",
    "\n",
    "- Dropout is a regularization technique, which affects only the training process (**during evaluation, it is not active**). The goal of dropout is **reduce unnecessary feature dependencies in the network, allowing it to be simpler and improves its generalization abilities (reduces overfitting)**. In simple terms, it helps the model to learn that some features are an \"OR\" and not an \"AND\" requirements.\n",
    "\n",
    "- Max-pooling is not a regularization technique and it is part of the model's architecture, so it is **also used during evaluation**. The goal of max-pooling is to **down-sample an input representation. As a result the model becomes less sensitive to some translations (improving translation invariance).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "952fe06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN structure\n",
    "def multilayer_perceptron(x, weights, biases, keep_prob):\n",
    "    layer_1 = tf.add(tf.matmul(x, tf.multiply(weights['h1'], partition)), biases['b1']) # incoperate partition with weight 1\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    if max_pooling:\n",
    "        layer_1 = max_pool(layer_1)\n",
    "    if droph1:\n",
    "        layer_1 = tf.nn.dropout(layer_1, keep_prob=keep_prob)\n",
    "\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_2 = tf.nn.dropout(layer_2, keep_prob=keep_prob)\n",
    "\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    ## Do not use batch-norm\n",
    "    # layer_3 = tf.contrib.layers.batch_norm(layer_3, center=True, scale=True,\n",
    "    #                                   is_training=is_training)\n",
    "    layer_3 = tf.nn.relu(layer_3)\n",
    "    layer_3 = tf.nn.dropout(layer_3, keep_prob=keep_prob)\n",
    "\n",
    "    out_layer = tf.matmul(layer_3, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f70c0",
   "metadata": {},
   "source": [
    "# initiate components for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f10f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_features])\n",
    "y = tf.placeholder(tf.int32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "lr = tf.placeholder(tf.float32)\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal(shape=[n_features, n_hidden_1], stddev=0.1)),\n",
    "    'h2': tf.Variable(tf.truncated_normal(shape=[n_hidden_1, n_hidden_2], stddev=0.1)),\n",
    "    'h3': tf.Variable(tf.truncated_normal(shape=[n_hidden_2, n_hidden_3], stddev=0.1)),\n",
    "    'out': tf.Variable(tf.truncated_normal(shape=[n_hidden_3, n_classes], stddev=0.1))\n",
    "\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.zeros([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.zeros([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.zeros([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c55eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
